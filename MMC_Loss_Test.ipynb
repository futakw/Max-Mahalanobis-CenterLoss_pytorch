{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.utils\n",
    "from torchvision import models\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from attack import Attack\n",
    "sys.path.append('./attacks')\n",
    "from fgsm import FGSM\n",
    "from pgd import PGD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "mean, std = [0.4914, 0.4822, 0.4465 ], [ 0.2023, 0.1994, 0.2010 ], \n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean,std),\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "\n",
    "\n",
    "cifar10_train = dsets.CIFAR10(root='./data', train=True,\n",
    "                                       download=True, transform=train_transform)\n",
    "cifar10_test  = dsets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=test_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar10_train, batch_size=50,\n",
    "                                         shuffle=True, num_workers=1)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(cifar10_test, batch_size=50,\n",
    "                                        shuffle=False, num_workers=1)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, title):\n",
    "    npimg = img.numpy()\n",
    "    fig = plt.figure(figsize = (20, 50))\n",
    "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_opt_means(C, p, L): \n",
    "    \"\"\"\n",
    "    input\n",
    "        C = constant value\n",
    "        p = dimention of feature vector\n",
    "        L = class number\n",
    "    \"\"\"\n",
    "    opt_means = np.zeros((L, p))\n",
    "    opt_means[0][0] = 1\n",
    "    for i in range(1,L):\n",
    "        for j in range(i): \n",
    "            opt_means[i][j] = - (1/(L-1) + np.dot(opt_means[i],opt_means[j])) / opt_means[j][j]\n",
    "        opt_means[i][i] = np.sqrt(1 - np.linalg.norm(opt_means[i])**2)\n",
    "    for k in range(L):\n",
    "        opt_means[k] = C * opt_means[k]\n",
    "        \n",
    "    return opt_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MM_LDA(nn.Module):\n",
    "    def __init__(self, C, n_dense, class_num, device, Normalize=False):\n",
    "        super().__init__()\n",
    "        self.C = C\n",
    "        self.class_num = class_num\n",
    "        opt_means = generate_opt_means(C, n_dense, class_num)\n",
    "        self.mean_expand = torch.tensor(opt_means).unsqueeze(0).double().to(device) # (1, num_class, num_dense)\n",
    "        self.Normalize = Normalize\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         print('x', x, x.shape)\n",
    "        b, p = x.shape # batch_size, num_dense\n",
    "        L = self.class_num\n",
    "        if self.Normalize: # 正規化する\n",
    "            x = (x / (torch.norm(x, p=2, dim=1, keepdim=True) + 1e-10)) * self.C\n",
    "#             print(torch.norm(x, p=2, dim=1, keepdim=True))\n",
    "            \n",
    "        x_expand =  x.repeat(1,L).view(b, L, p).double() # (batch_size, num_class, num_dense)\n",
    "\n",
    "        logits = - torch.sum((x_expand - self.mean_expand)**2, dim=2) # (batch_size, num_class)\n",
    "#         print('x-mean',x_expand - self.mean_expand)\n",
    "#         print('logits', logits, logits.shape)\n",
    " \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_normal_data(model):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "\n",
    "        images = images.cuda()\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.cuda()).sum()\n",
    "\n",
    "    print('Accuracy of Clean images: %f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_AEs(model, attack='PGD'):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    fgsm_attack = FGSM(model, eps=0.12) #Benchmarking Adversarial Robustness on Image Classificationの設定\n",
    "    pgd_attack = PGD(model, eps=8/255, alpha=2/255, steps=10)\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        \n",
    "        if attack=='PGD':\n",
    "            adv_images = pgd_attack(images, labels ).cuda()\n",
    "        elif attack=='FGSM':\n",
    "            adv_images = fgsm_attack(images, labels ).cuda()\n",
    "    #     adv_images_norm = norm(adv_images)\n",
    "\n",
    "        outputs = model(adv_images)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.cuda()).sum()\n",
    "\n",
    "    print('Accuracy on Adversarial images: %f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_examples(model, attack='PGD', eps=8/255):\n",
    "    images, labels = iter(test_loader).next()\n",
    "    t = 20\n",
    "    idx = list(range(t,t+8))\n",
    "\n",
    "    print('Normal')\n",
    "    imshow(torchvision.utils.make_grid(images[idx], normalize=True), [classes[int(i)] for i in labels[idx]])\n",
    "    _ , pred_labels = torch.max(model(images.cuda()), 1)\n",
    "    print('Predicted Label:', [classes[int(i)] for i in pred_labels[idx]])\n",
    "\n",
    "    print('------------------------------------')\n",
    "\n",
    "    fgsm_attack = FGSM(model, eps=eps)\n",
    "    pgd_attack = PGD(model, eps=eps, alpha=2/255, steps=10)\n",
    "\n",
    "    if attack=='PGD':\n",
    "        adv_images = pgd_attack(images, labels )\n",
    "    elif attack=='FGSM':\n",
    "        adv_images = fgsm_attack(images, labels )\n",
    "    #norm_adv_images = norm(adv_images)\n",
    "\n",
    "    print('Adversarial')\n",
    "    imshow(torchvision.utils.make_grid(adv_images.cpu().data[idx], normalize=True), [classes[int(i)] for i in labels[idx]])\n",
    "\n",
    "    outputs = model(adv_images.cuda())\n",
    "    _, pred_labels = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted Label:', [classes[int(i)] for i in pred_labels[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MMC\n",
    "\n",
    "file_name = './exps/checkpoint_resnet34_MMC_norm/ckpt.pth'\n",
    "\n",
    "model = models.resnet34(pretrained=False)\n",
    "model.fc = nn.Linear(512,256) # use_dense\n",
    "# MM_LDA \n",
    "C, n_dense, class_num = 10, 256, 10\n",
    "mm_lda_layer = MM_LDA(C, n_dense, class_num, device, Normalize=True) \n",
    "#activation = nn.Softmax(1)\n",
    "model = nn.Sequential(model, mm_lda_layer) # , activation) # テスト時はsoftmaxするため\n",
    "model = model.to(device)\n",
    "\n",
    "checkpoint = torch.load(file_name)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_on_normal_data(model)\n",
    "for attack in ['PGD','FGSM']:\n",
    "    print(attack)\n",
    "    test_on_AEs(model, attack=attack)\n",
    "    show_examples(model, attack=attack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.MM_LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MM_LDA\n",
    "\n",
    "file_name = './exps/checkpoint_resnet34_MMLDA/ckpt.pth'\n",
    "\n",
    "model = models.resnet34(pretrained=False)\n",
    "model.fc = nn.Linear(512,256) # use_dense\n",
    "# MM_LDA \n",
    "C, n_dense, class_num = 100, 256, 10\n",
    "mm_lda_layer = MM_LDA(C, n_dense, class_num, device, Normalize=True) \n",
    "#activation = nn.Softmax(1)\n",
    "model = nn.Sequential(model, mm_lda_layer) # , activation) # テスト時はsoftmaxするため\n",
    "model = model.to(device)\n",
    "\n",
    "checkpoint = torch.load(file_name)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Clean images: 62.290000 %\n",
      "PGD\n"
     ]
    }
   ],
   "source": [
    "test_on_normal_data(model)\n",
    "for attack in ['PGD','FGSM']:\n",
    "    print(attack)\n",
    "    test_on_AEs(model, attack=attack)\n",
    "    show_examples(model, attack=attack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './exps/checkpoint_resnet34/ckpt.pth'\n",
    "model = models.resnet34(pretrained=False)\n",
    "model.fc = nn.Linear(512,10) #for CIFAR10\n",
    "model = model.to(device)\n",
    "\n",
    "checkpoint = torch.load(file_name)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_on_normal_data(model)\n",
    "for attack in ['PGD','FGSM']:\n",
    "    print(attack)\n",
    "    test_on_AEs(model, attack=attack)\n",
    "    show_examples(model, attack=attack)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
